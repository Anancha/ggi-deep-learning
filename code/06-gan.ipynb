{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative adversarial networks\n",
    "\n",
    "Adapted from [Pytorch tutorial for Deep Learning researchers](https://github.com/yunjey/pytorch-tutorial) (Yunvey Choi, 2018).\n",
    "\n",
    "Used as part of Deep Learning, Gilles Louppe, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "sample_dir = 'samples'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Image processing\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n",
    "                                     std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "# MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(root='./data/',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())\n",
    "\n",
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setting\n",
    "D = D.to(device)\n",
    "G = G.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def denorm(x):\n",
    "    out = (x + 1) / 2\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/200], Step [200/600], d_loss: 0.2391, g_loss: 3.9146, D(x): 0.91, D(G(z)): 0.04\n",
      "Epoch [0/200], Step [400/600], d_loss: 0.2974, g_loss: 3.8616, D(x): 0.96, D(G(z)): 0.15\n",
      "Epoch [0/200], Step [600/600], d_loss: 0.2534, g_loss: 3.2607, D(x): 0.92, D(G(z)): 0.09\n",
      "Epoch [1/200], Step [200/600], d_loss: 0.3403, g_loss: 4.2874, D(x): 0.94, D(G(z)): 0.15\n",
      "Epoch [1/200], Step [400/600], d_loss: 0.3541, g_loss: 3.7665, D(x): 0.85, D(G(z)): 0.04\n",
      "Epoch [1/200], Step [600/600], d_loss: 0.4785, g_loss: 3.9160, D(x): 0.85, D(G(z)): 0.06\n",
      "Epoch [2/200], Step [200/600], d_loss: 0.4287, g_loss: 3.0579, D(x): 0.86, D(G(z)): 0.10\n",
      "Epoch [2/200], Step [400/600], d_loss: 0.3306, g_loss: 3.0286, D(x): 0.85, D(G(z)): 0.05\n",
      "Epoch [2/200], Step [600/600], d_loss: 0.4675, g_loss: 3.8040, D(x): 0.88, D(G(z)): 0.14\n",
      "Epoch [3/200], Step [200/600], d_loss: 0.3064, g_loss: 3.4581, D(x): 0.89, D(G(z)): 0.09\n",
      "Epoch [3/200], Step [400/600], d_loss: 0.5488, g_loss: 2.7006, D(x): 0.84, D(G(z)): 0.15\n",
      "Epoch [3/200], Step [600/600], d_loss: 0.4769, g_loss: 2.9240, D(x): 0.81, D(G(z)): 0.05\n",
      "Epoch [4/200], Step [200/600], d_loss: 0.3905, g_loss: 4.0799, D(x): 0.86, D(G(z)): 0.08\n",
      "Epoch [4/200], Step [400/600], d_loss: 0.5660, g_loss: 2.7659, D(x): 0.85, D(G(z)): 0.16\n",
      "Epoch [4/200], Step [600/600], d_loss: 0.3511, g_loss: 2.7101, D(x): 0.93, D(G(z)): 0.18\n",
      "Epoch [5/200], Step [200/600], d_loss: 0.3670, g_loss: 2.2214, D(x): 0.88, D(G(z)): 0.13\n",
      "Epoch [5/200], Step [400/600], d_loss: 0.5179, g_loss: 3.6914, D(x): 0.87, D(G(z)): 0.16\n",
      "Epoch [5/200], Step [600/600], d_loss: 0.3936, g_loss: 3.3095, D(x): 0.87, D(G(z)): 0.11\n",
      "Epoch [6/200], Step [200/600], d_loss: 0.6472, g_loss: 3.5559, D(x): 0.78, D(G(z)): 0.08\n",
      "Epoch [6/200], Step [400/600], d_loss: 0.3558, g_loss: 2.9090, D(x): 0.90, D(G(z)): 0.16\n",
      "Epoch [6/200], Step [600/600], d_loss: 0.2580, g_loss: 3.3821, D(x): 0.90, D(G(z)): 0.08\n",
      "Epoch [7/200], Step [200/600], d_loss: 0.2169, g_loss: 4.9775, D(x): 0.94, D(G(z)): 0.10\n",
      "Epoch [7/200], Step [400/600], d_loss: 0.3049, g_loss: 3.9638, D(x): 0.94, D(G(z)): 0.15\n",
      "Epoch [7/200], Step [600/600], d_loss: 0.2227, g_loss: 2.9752, D(x): 0.93, D(G(z)): 0.10\n",
      "Epoch [8/200], Step [200/600], d_loss: 0.4782, g_loss: 3.0415, D(x): 0.81, D(G(z)): 0.07\n",
      "Epoch [8/200], Step [400/600], d_loss: 0.3926, g_loss: 3.9021, D(x): 0.83, D(G(z)): 0.05\n",
      "Epoch [8/200], Step [600/600], d_loss: 0.3577, g_loss: 3.2959, D(x): 0.86, D(G(z)): 0.07\n",
      "Epoch [9/200], Step [200/600], d_loss: 0.4025, g_loss: 2.5167, D(x): 0.90, D(G(z)): 0.18\n",
      "Epoch [9/200], Step [400/600], d_loss: 0.4677, g_loss: 2.1613, D(x): 0.90, D(G(z)): 0.21\n",
      "Epoch [9/200], Step [600/600], d_loss: 0.7924, g_loss: 2.6187, D(x): 0.75, D(G(z)): 0.15\n",
      "Epoch [10/200], Step [200/600], d_loss: 0.2931, g_loss: 3.8865, D(x): 0.91, D(G(z)): 0.11\n",
      "Epoch [10/200], Step [400/600], d_loss: 0.4588, g_loss: 2.4235, D(x): 0.90, D(G(z)): 0.18\n",
      "Epoch [10/200], Step [600/600], d_loss: 0.6287, g_loss: 2.8367, D(x): 0.75, D(G(z)): 0.08\n",
      "Epoch [11/200], Step [200/600], d_loss: 0.6250, g_loss: 3.1771, D(x): 0.76, D(G(z)): 0.07\n",
      "Epoch [11/200], Step [400/600], d_loss: 0.5572, g_loss: 2.6054, D(x): 0.84, D(G(z)): 0.22\n",
      "Epoch [11/200], Step [600/600], d_loss: 0.5638, g_loss: 2.3613, D(x): 0.94, D(G(z)): 0.29\n",
      "Epoch [12/200], Step [200/600], d_loss: 0.5281, g_loss: 2.2320, D(x): 0.87, D(G(z)): 0.19\n",
      "Epoch [12/200], Step [400/600], d_loss: 0.6208, g_loss: 2.2174, D(x): 0.78, D(G(z)): 0.13\n",
      "Epoch [12/200], Step [600/600], d_loss: 0.6211, g_loss: 2.5398, D(x): 0.82, D(G(z)): 0.18\n",
      "Epoch [13/200], Step [200/600], d_loss: 0.5543, g_loss: 2.5996, D(x): 0.83, D(G(z)): 0.19\n",
      "Epoch [13/200], Step [400/600], d_loss: 0.4563, g_loss: 2.4698, D(x): 0.86, D(G(z)): 0.17\n",
      "Epoch [13/200], Step [600/600], d_loss: 0.3730, g_loss: 3.5483, D(x): 0.86, D(G(z)): 0.12\n",
      "Epoch [14/200], Step [200/600], d_loss: 0.7284, g_loss: 2.5084, D(x): 0.79, D(G(z)): 0.22\n",
      "Epoch [14/200], Step [400/600], d_loss: 0.4472, g_loss: 3.0495, D(x): 0.80, D(G(z)): 0.09\n",
      "Epoch [14/200], Step [600/600], d_loss: 0.6781, g_loss: 3.2309, D(x): 0.79, D(G(z)): 0.17\n",
      "Epoch [15/200], Step [200/600], d_loss: 0.5222, g_loss: 3.0752, D(x): 0.86, D(G(z)): 0.19\n",
      "Epoch [15/200], Step [400/600], d_loss: 0.5690, g_loss: 3.2223, D(x): 0.79, D(G(z)): 0.14\n",
      "Epoch [15/200], Step [600/600], d_loss: 0.6027, g_loss: 2.8525, D(x): 0.81, D(G(z)): 0.17\n",
      "Epoch [16/200], Step [200/600], d_loss: 0.4549, g_loss: 2.7204, D(x): 0.87, D(G(z)): 0.17\n",
      "Epoch [16/200], Step [400/600], d_loss: 0.4551, g_loss: 3.2554, D(x): 0.85, D(G(z)): 0.14\n",
      "Epoch [16/200], Step [600/600], d_loss: 0.3815, g_loss: 2.8581, D(x): 0.92, D(G(z)): 0.19\n",
      "Epoch [17/200], Step [200/600], d_loss: 0.3507, g_loss: 3.8484, D(x): 0.88, D(G(z)): 0.13\n",
      "Epoch [17/200], Step [400/600], d_loss: 0.5235, g_loss: 3.1945, D(x): 0.84, D(G(z)): 0.15\n",
      "Epoch [17/200], Step [600/600], d_loss: 0.4489, g_loss: 3.2870, D(x): 0.89, D(G(z)): 0.19\n",
      "Epoch [18/200], Step [200/600], d_loss: 0.6452, g_loss: 3.9283, D(x): 0.85, D(G(z)): 0.23\n",
      "Epoch [18/200], Step [400/600], d_loss: 0.7729, g_loss: 2.4540, D(x): 0.85, D(G(z)): 0.29\n",
      "Epoch [18/200], Step [600/600], d_loss: 0.2600, g_loss: 4.0272, D(x): 0.91, D(G(z)): 0.10\n",
      "Epoch [19/200], Step [200/600], d_loss: 0.5353, g_loss: 2.8334, D(x): 0.83, D(G(z)): 0.15\n",
      "Epoch [19/200], Step [400/600], d_loss: 0.4072, g_loss: 1.9685, D(x): 0.90, D(G(z)): 0.17\n",
      "Epoch [19/200], Step [600/600], d_loss: 0.7789, g_loss: 3.2131, D(x): 0.67, D(G(z)): 0.05\n",
      "Epoch [20/200], Step [200/600], d_loss: 0.4854, g_loss: 3.1083, D(x): 0.86, D(G(z)): 0.19\n",
      "Epoch [20/200], Step [400/600], d_loss: 0.7254, g_loss: 2.7252, D(x): 0.81, D(G(z)): 0.21\n",
      "Epoch [20/200], Step [600/600], d_loss: 0.6115, g_loss: 2.6173, D(x): 0.77, D(G(z)): 0.16\n",
      "Epoch [21/200], Step [200/600], d_loss: 0.5661, g_loss: 3.0151, D(x): 0.87, D(G(z)): 0.21\n",
      "Epoch [21/200], Step [400/600], d_loss: 0.5621, g_loss: 2.8405, D(x): 0.79, D(G(z)): 0.15\n",
      "Epoch [21/200], Step [600/600], d_loss: 0.5779, g_loss: 2.3811, D(x): 0.82, D(G(z)): 0.17\n",
      "Epoch [22/200], Step [200/600], d_loss: 0.4724, g_loss: 3.1651, D(x): 0.89, D(G(z)): 0.22\n",
      "Epoch [22/200], Step [400/600], d_loss: 0.6048, g_loss: 1.9476, D(x): 0.79, D(G(z)): 0.19\n",
      "Epoch [22/200], Step [600/600], d_loss: 0.5923, g_loss: 2.2605, D(x): 0.90, D(G(z)): 0.29\n",
      "Epoch [23/200], Step [200/600], d_loss: 0.7410, g_loss: 2.9925, D(x): 0.78, D(G(z)): 0.23\n",
      "Epoch [23/200], Step [400/600], d_loss: 0.4160, g_loss: 3.3050, D(x): 0.85, D(G(z)): 0.14\n",
      "Epoch [23/200], Step [600/600], d_loss: 0.4398, g_loss: 2.1586, D(x): 0.84, D(G(z)): 0.15\n",
      "Epoch [24/200], Step [200/600], d_loss: 0.5428, g_loss: 2.8635, D(x): 0.87, D(G(z)): 0.22\n",
      "Epoch [24/200], Step [400/600], d_loss: 0.5501, g_loss: 3.0423, D(x): 0.79, D(G(z)): 0.14\n",
      "Epoch [24/200], Step [600/600], d_loss: 0.5596, g_loss: 2.0953, D(x): 0.83, D(G(z)): 0.18\n",
      "Epoch [25/200], Step [200/600], d_loss: 0.6530, g_loss: 2.4149, D(x): 0.76, D(G(z)): 0.18\n",
      "Epoch [25/200], Step [400/600], d_loss: 0.5343, g_loss: 2.5538, D(x): 0.79, D(G(z)): 0.13\n",
      "Epoch [25/200], Step [600/600], d_loss: 0.4173, g_loss: 2.4323, D(x): 0.90, D(G(z)): 0.19\n",
      "Epoch [26/200], Step [200/600], d_loss: 0.7922, g_loss: 2.3385, D(x): 0.72, D(G(z)): 0.17\n",
      "Epoch [26/200], Step [400/600], d_loss: 0.6469, g_loss: 2.2096, D(x): 0.82, D(G(z)): 0.22\n",
      "Epoch [26/200], Step [600/600], d_loss: 0.6082, g_loss: 3.1833, D(x): 0.86, D(G(z)): 0.25\n",
      "Epoch [27/200], Step [200/600], d_loss: 0.5494, g_loss: 2.7407, D(x): 0.81, D(G(z)): 0.16\n",
      "Epoch [27/200], Step [400/600], d_loss: 0.5915, g_loss: 2.3795, D(x): 0.78, D(G(z)): 0.14\n",
      "Epoch [27/200], Step [600/600], d_loss: 0.4987, g_loss: 3.1413, D(x): 0.80, D(G(z)): 0.09\n",
      "Epoch [28/200], Step [200/600], d_loss: 0.4251, g_loss: 2.8542, D(x): 0.86, D(G(z)): 0.16\n",
      "Epoch [28/200], Step [400/600], d_loss: 0.4643, g_loss: 4.0777, D(x): 0.81, D(G(z)): 0.10\n",
      "Epoch [28/200], Step [600/600], d_loss: 0.3278, g_loss: 3.2583, D(x): 0.88, D(G(z)): 0.11\n",
      "Epoch [29/200], Step [200/600], d_loss: 0.4853, g_loss: 3.4546, D(x): 0.88, D(G(z)): 0.22\n",
      "Epoch [29/200], Step [400/600], d_loss: 0.4607, g_loss: 1.9960, D(x): 0.84, D(G(z)): 0.16\n",
      "Epoch [29/200], Step [600/600], d_loss: 0.3665, g_loss: 3.5870, D(x): 0.87, D(G(z)): 0.11\n",
      "Epoch [30/200], Step [200/600], d_loss: 0.7152, g_loss: 2.5107, D(x): 0.81, D(G(z)): 0.25\n",
      "Epoch [30/200], Step [400/600], d_loss: 0.4996, g_loss: 2.3389, D(x): 0.86, D(G(z)): 0.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/200], Step [600/600], d_loss: 0.6220, g_loss: 2.6426, D(x): 0.74, D(G(z)): 0.14\n",
      "Epoch [31/200], Step [200/600], d_loss: 0.4193, g_loss: 2.4237, D(x): 0.87, D(G(z)): 0.16\n",
      "Epoch [31/200], Step [400/600], d_loss: 0.5081, g_loss: 2.2481, D(x): 0.84, D(G(z)): 0.16\n",
      "Epoch [31/200], Step [600/600], d_loss: 0.5768, g_loss: 1.9821, D(x): 0.89, D(G(z)): 0.26\n",
      "Epoch [32/200], Step [200/600], d_loss: 0.5533, g_loss: 2.5554, D(x): 0.79, D(G(z)): 0.16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5e51221c8b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensor is not a torch image.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ggi/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i)\u001b[0m\n\u001b[1;32m    426\u001b[0m                           \u001b[0;34m'iterations executed (and might lead to errors or silently give '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m                           'incorrect results).', category=RuntimeWarning)\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "\n",
    "# Create the labels which are later used as input for the BCE loss\n",
    "real_labels = torch.ones(batch_size, 1).to(device)\n",
    "fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(data_loader):\n",
    "        images = images.reshape(batch_size, -1).to(device)\n",
    "        \n",
    "        ## Train D\n",
    "\n",
    "        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n",
    "        # Second term of the loss is always zero since real_labels == 1\n",
    "        outputs = D(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "        \n",
    "        # Compute BCELoss using fake images\n",
    "        # First term of the loss is always zero since fake_labels == 0\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        ## Train G\n",
    "\n",
    "        # Compute loss with fake images\n",
    "        z = torch.randn(batch_size, latent_size).to(device)\n",
    "        fake_images = G(z)\n",
    "        outputs = D(fake_images)\n",
    "        \n",
    "        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "        if (i+1) % 200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "    \n",
    "    # Save real images\n",
    "    if (epoch+1) == 1:\n",
    "        images = images.reshape(images.size(0), 1, 28, 28)\n",
    "        save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n",
    "    \n",
    "    # Save sampled images\n",
    "    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n",
    "\n",
    "# Save the model checkpoints \n",
    "torch.save(G.state_dict(), 'G.ckpt')\n",
    "torch.save(D.state_dict(), 'D.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
